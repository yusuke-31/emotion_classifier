import os
import io
import pickle
import requests
import streamlit as st
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
import torch
import spacy
import japanize_matplotlib

from huggingface_hub import login, HfApi
from transformers import AutoTokenizer, AutoModelForSequenceClassification

# --- HFãƒˆãƒ¼ã‚¯ãƒ³å–å¾—ï¼†ãƒ­ã‚°ã‚¤ãƒ³ ---
hf_token = st.secrets["HF_TOKEN"] # secretsã« "HF_TOKEN" ã‚’è¨­å®šã—ã¦ãŠãã“ã¨
api = HfApi(token=hf_token)

# --- ãƒ¢ãƒ‡ãƒ«ãƒªãƒã‚¸ãƒˆãƒªæŒ‡å®š ---
model_repo = "yusuke-31/streamlit_deploy1"

# --- transformersã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ï¼†ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼èª­ã¿è¾¼ã¿ ---
@st.cache_resource(show_spinner="ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™â€¦")
def load_model_and_tokenizer():
    model = AutoModelForSequenceClassification.from_pretrained(model_repo, use_auth_token=hf_token)
    tokenizer = AutoTokenizer.from_pretrained(model_repo, use_auth_token=hf_token)
    model.eval()  # ä¸€åº¦ã ã‘å‘¼ã¶
    return model, tokenizer

model, tokenizer = load_model_and_tokenizer()

# --- extra_info.pkl ã‚’Hubã‹ã‚‰å–å¾— ---
@st.cache_data(show_spinner="æ„Ÿæƒ…ãƒ©ãƒ™ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™â€¦")
def load_extra_info():
    extra_info_url = f"https://huggingface.co/{model_repo}/resolve/main/extra_info.pkl"
    headers = {"Authorization": f"Bearer {hf_token}"}
    response = requests.get(extra_info_url, headers=headers)
    return pickle.load(io.BytesIO(response.content))

extra_info = load_extra_info()
emotion_names = extra_info["emotion_names"]

# --- Softmaxé–¢æ•° ---
def np_softmax(x):
    e_x = np.exp(x - np.max(x))
    return e_x / e_x.sum()

# --- æ„Ÿæƒ…åˆ†æé–¢æ•° ---
def analyze_emotion(text):
    tokens = tokenizer(text, truncation=True, return_tensors="pt")
    tokens = {k: v.to(model.device) for k, v in tokens.items()}
    with torch.no_grad():
        preds = model(**tokens)
    prob = np_softmax(preds.logits.cpu().numpy()[0])
    return {n: p for n, p in zip(emotion_names, prob)}

# --- GiNZAãƒ­ãƒ¼ãƒ‰ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãï¼‰ ---
@st.cache_resource(show_spinner="æ—¥æœ¬èªæ§‹æ–‡è§£æã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆGiNZAï¼‰ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™â€¦")
def load_nlp():
    return spacy.load("ja_ginza")

nlp = load_nlp()

# --- æ–‡åˆ†å‰²é–¢æ•° ---
def split_sentences(text):
    doc = nlp(text)
    return [sent.text.strip() for sent in doc.sents if sent.text.strip()]

# --- Streamlit UI ---
st.title("ğŸŒˆ æ—¥æœ¬èªæ–‡ï¼†æ„Ÿæƒ…åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")

user_input = st.text_area(
    "ğŸ“ æ—¥æœ¬èªã®æ–‡ç« ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼š",
    "ä»Šã®ã‚ãªãŸã®æ°—æŒã¡ã¯ã©ã®ã‚ˆã†ãªã‚‚ã®ã§ã—ã‚‡ã†ã€‚èª¿æŸ»ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚",
    height=200,
)

if st.button("ğŸ¯ æ–‡ã‚’åˆ†æã™ã‚‹"):
    if not user_input.strip():
        st.warning("å…¥åŠ›ãŒã‚ã‚Šã¾ã›ã‚“ãƒ»ãƒ»ãƒ»")
    else:
        paragraphs = [p.strip() for p in user_input.split('\n') if p.strip()]
        all_sentences = []
        for para in paragraphs:
            all_sentences.extend(split_sentences(para))

        if not all_sentences:
            st.warning("æ–‡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æ”¹è¡Œã¾ãŸã¯å¥èª­ç‚¹ã®ã‚ã‚‹æ–‡ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        else:
            all_results = []
            for idx, sentence in enumerate(all_sentences):
                result = analyze_emotion(sentence)
                result["æ–‡"] = sentence
                result["ID"] = idx + 1
                all_results.append(result)

            df_result = pd.DataFrame(all_results)
            df_result = df_result[["ID", "æ–‡"] + emotion_names]

            st.success(f"{len(df_result)} æ–‡ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚")
            st.dataframe(df_result, use_container_width=True)

            # --- å¹³å‡ã‚°ãƒ©ãƒ• ---
            mean_emotions = df_result[emotion_names].mean().reset_index()
            mean_emotions.columns = ["æ„Ÿæƒ…", "å¹³å‡ç¢ºç‡"]

            st.write("### ğŸ“Š å…¨ä½“ã®å¹³å‡æ„Ÿæƒ…ã‚¹ã‚³ã‚¢")
            plt.figure(figsize=(8, 3))
            sns.barplot(x="æ„Ÿæƒ…", y="å¹³å‡ç¢ºç‡", data=mean_emotions)
            st.pyplot(plt.gcf())

            # --- æ–‡ã”ã¨ã®æ„Ÿæƒ…ã‚¹ã‚³ã‚¢æ£’ã‚°ãƒ©ãƒ•ï¼ˆä»»æ„ï¼‰ ---
            st.write("### ğŸ” å„æ–‡ã®æ„Ÿæƒ…ã‚¹ã‚³ã‚¢")
            for _, row in df_result.iterrows():
                st.write(f"**æ–‡{int(row['ID'])}: {row['æ–‡']}**")
                scores = row[emotion_names]
                fig, ax = plt.subplots(figsize=(6, 2))
                sns.barplot(x=scores.index, y=scores.values, ax=ax)
                ax.set_ylim(0, 1)
                st.pyplot(fig)

# --- Hugging Face ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ UI ---
st.markdown("---")
st.header("ğŸš€ ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚©ãƒ«ãƒ€ã‚’Hugging Face Hub ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")

local_folder = st.text_input("ğŸ“ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", "saved_model")

if st.button("ğŸ“¤ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰é–‹å§‹"):
    if not os.path.isdir(local_folder):
        st.error(f"æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {local_folder}")
    else:
        try:
            with st.spinner("Hugging Face Hub ã¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­â€¦"):
                api.upload_folder(
                    folder_path=local_folder,
                    repo_id=model_repo,
                    repo_type="model",
                    ignore_patterns=["*.git*", "*.zip"],
                )
            st.success("âœ… ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        except Exception as e:
            st.error(f"âŒ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
